Unstructured data may contain text, images, audio files, and even video files. Given the differences in these types of data, traditional methods for cleaning and analysing these kind of data are not as helpful. Nevertheless, there are ways to work with these data in R. In these upcoming lessons, we'll introduce a number of different types of unstructured data and then give you a brief example of where you would start if you wanted to work with each unconventional data type in R. 

While most of the data we've seen so far has been text stored in rows and columns within a spreadsheet, text documents or words of any kind can also be data! Text analytics or text mining is the process of taking large collections of text, generating a dataset from the that can be analysed, and analysing the words in that dataset. In other words, text mining is the process of converting textual data from unstructured form to a structured form for analysis or visualization.

While not the most typical type of data analysed in R, R can be used to analyse text. There are three packages that are particularly helpful for analysing textual data using text mining: T M, which is a text mining package, language R, a statistical analysis of linguistic data package and tidy text: a tidy analysis package which works with tidy data tools (eg: D plier). To see an example of text analysis in R, check out David Robinson's post: Text analysis of Trump's tweets confirms he writes only the (angrier) Android half, where he uses the tidy text package, twit R package, and Twitter API to analyse the tweets from Donald Trump during his presidential campaign.

There are plenty of different ways to get (mine) and analyse text data, but here, we will go over a few of the ways we can analyse text using the tidy text package. This lesson will closely follow the first two chapters of the tidy text book. Before we get into it, first, let's install and load it. The tidy text package is used to convert text into a tidy format that is compatible with all the other tidy verse packages that we have looked at (eg: D plier), which makes it a great place to start learning how to analyse text within R. . Let's get some text and convert it to a tidy format! 

We'll go back to using some of the free text available on Project Gutenberg. Thankfully, there's an R package, gutenberg R, that allows you to access all of their texts! Install and load it now.

Let's find the text for "Dracula". To do so, we use the gutenberg works function to find information about how it is stored in the Gutenberg database. So using the gutenberg works function, we filter for books with the title Dracula. We can see from this output, that Dracula has an ID of 345, which we will use in the next function, gutenberg download to get the text. So now we have a dataframe, called dracula, that contains the entire text of the novel! The first step of analysing this text with the tidy text package is to convert sentences and paragraphs to a format where each word is on its own line. This process is called tokenization. 

A token is a "meaningful unit of text", which in our case means words, but in other scenarios could be sentences or even paragraphs. We are going to use the tidy text function, unnest tokens to separate the full text of Dracula, currently stored in the text column of the dataframe dracula into one line per word. This step also converts all words to lowercase text and removes punctuation, which we don't necessarily want in our analyses. After doing this, you can see that there is one word per line. From here, we could jump right into analysis, but another common step of text analysis is to remove common words, like "the", "of", or "at". 

Stop words are common words that you would like removed from your analysis due to how common they are. The tidy text package conveniently has a list of these words, kept in the dataset stop words. We can use an anti join to remove these stop words from our Dracula text.

From here, we have a tidied dataset containing the filtered text of Dracula, which we can now choose to analyse in multiple ways! One common thing we can do is to count the frequency of words used in the text and plot them. To do so, we will use D pliers count function to find the most common words used in Dracula. Just looking at the first few lines, we can see that "time", "van", "night", and "helsing" are the top four words most commonly used in Dracula. 

To plot our results, we can either use our old friend G G plot, to create a bar plot of these common words and their frequencies, or we could make a word cloud. Let's start with the bar chart, where we will see which words are used greater than 150 times. As before, first we will Put each word on its own line using unnest tokens. We will then use anti-join to Remove common "stop" words. Next we will Count the number of times each word appears and use filter to Keep only those that appear more than 150 times. Finally, we will use mutate to Put them in the order they appear, so that when we use  G G plot to Plot the number of times each word appears, they will be in order of most to least frequent. Finally, we will use geom bar to create a bar plot and use co-ordinate flip to swap the axees so that the words are on the Y.

This results in a  plot of the most common words used in Dracula. 

A similar procedure is used to create a word cloud, but requires the installation of another package, aptly named word cloud. Install and load this now. A word cloud is a representation of the most common words in a text sample, with each word's size determined by its frequency - the more frequent a word, the larger it appears. Let's use this package to create a word cloud of the 75 most common words in Dracula. Repeat the same steps from before where we tokenize the text of Dracula, remove stop words, and count the number of times each word appears. Then using the word cloud package, plot the 75 most frequent words. 

And there we have a slightly less scientific looking plot, with a bit more style, showing the most common words appearing in Dracula. From this cloud, we can get a sense of the tone of Dracula, with some of the common words being "dead", "blood", "fear", "poor" and, "terrible". But we can get a bit more rigorous in this and perform sentiment analysis.

In sentiment analysis, the goal is to categorize the text and quantify opinions and emotions expressed within the text. For instance, in a lot of satisfaction surveys, as you may have taken, the company asks you to express your opinion about your experience or a specific product in a few sentences. Historically, due to the fact that survey respondents could have typed anything they wanted in these boxes, these kind of data were often ignored when analysing the survey data due to their unstructured nature. In other words, free text responses on a survey can be hard to analyse. In cases where these data were analysed, the text from each survey respondent would have been read by a human. That human would assess what the response and assign a score as to how positive or negative the text was. However, using sentiment analysis we are now able to read a vast amount of textual data and use an algorithm to assign a value to a respondent's attitude toward the service or the product. There are different approaches to sentiment analysis. Sometimes, a paragraph of text will be evaluated to assess how sad or happy the words in the text are. Other times, you'll use sentiment analysis to gauge how positive or negative the words in the text are. Other times still, words will be analysed using sentiment analysis to determine how scientific or unscientific text is. For more on sentiment analysis read the provided article.

Here, we will use sentiment analysis to look at whether Dracula is as dark as our word cloud would suggest. Within the tidy text package, they provide a list of words and their connotations within the sentiment dataset. They score words on the basis of three different sources and here, we are going to use the "bing" database, which scores words purely on "positive" or "negative", which we can view using the get sentiments function. You can see that there is a long list of words that are scored for being positive or negative. 

Now we will see if these positive or negative words are more common in Dracula. We will tokenize the text and remove stop words like before, but this time we will follow it with an inner join to find only those words in Dracula that match with either positive or negative words in the "bing" dataset and then we will count the number of times each appears, and sort by their popularity. Doing so, we see that seven of the top ten most common sentiments are negative words! It definitely seems like Dracula is a gloomy book! 

Let's plot this to see just how much more common the top ten negative words are than the top ten positive. We'll do the same as before, where we tokenize, remove stop words, join with the bing sentiments and count the number of times each positive or negative word appears. Next we group the words into positive and negative groups and use top N to Find the top ten most common words in both the positive and negative groups. Next we will ungroup this data so that mutate works in the next step, where we will Reorder the words so that when you plot them it will be in order of most common to least. Finally, we will use G G plot to Plot the words and their frequencies In a bar plot, using facet wrap to create two separate plots, one for each sentiment, where the X and Y axees are flipped for readability.

From this, we can see that the top negative words are used far more frequently than even the most frequently used positive words! 

In this lesson, we looked at how to manipulate and analyse text data in R, introducing the packages T M, language R, and in particular tidy text. We looked more into the tidy text package, were we learned what tokens are and what stop words are and how to get rid of them. We then analyzed our text data by counting and plotting common words (either in a bar plot or a word cloud). From there, we looked at sentiment analysis and examined the distribution of positive and negative words in Dracula and saw that negative words are more common than positive ones. 