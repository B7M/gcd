In this lesson, we'll discuss a few of the main file types used to store tabular data. To review briefly, tabular data are the type of data stored in spreadsheets. Information from different variables are stored in columns and each observation is stored in a different row. The values for each observation is stored in its respective cell.

Comma-separated values or CSV files allow us to store tabular data in a simple format. CSVs are plain-text files, which means that all the important information in the file is represented by text (where text is numbers, letters, and symbols you can type on your keyboard). For example, consider a dataset that includes information about the heights and blood types of three individuals. You could make a table that has three columns (names, heights, and blood types) and three rows (one for each person) in Google Sheets or Microsoft Excel. However, there is a better way of storing this data in plain text without needing to put them in table format. CSVs are a perfect way to store these data. In the CSV format, the values of each column for each person in the data are separated by commas and each row (each person in our case) is separated by a new line. Notice that CSV files have a dot CSV extension at the end. You can see this above at the top of the file. One of the advantages of CSV files is their simplicity. Because of this, they are one of the most common file formats used to store tabular data. Additionally, because they are plain text, they are compatible with many different types of software. CSVs can be read by most programs. Specifically, for our purposes, these files can be easily read into R, where they can be better understood by the human eye. 

Here, you see the same CSV opened in Google Sheets, where it's more easily interpretable by the human eye. As with any file type, CSVs do have their limitations. Specifically, CSV files are best used for data that have a consistent number of variables across observations. For example, in our example, there are three variables for each observation: "name", "height", and "blood type". If, however, you had eye color and weight for the second observation, but not for the other rows, you'd have a different number of variables for the second observation than the other two. This type of data is not best suited for CSVs. However, whenever you have information with the same number of variables across all observations, CSVs are a good bet!

Often, you will either be given the data or input the data yourself into a spreadsheet program, like Excel or Google Sheets. To create a dot CSV file from these files to be read into R, you will either click File then Save as and change the file format to comma separated values (dot CSV) for Excel, or for Google Slides, you will click File, Download and again change the file format to CSV. For practice, click on the provided link and download the Google Sheet as a CSV. 

Now that you have a CSV file, let's discuss how to get it into R! First, you must know the location of your CSV - you will either refer to this location by its path or, more ideally, if you are working within an R project, you should move your CSV to your "raw underscore data" folder that you created at the beginning of the project, and that becomes the path to your file. While the file has now been placed in the appropriate folder within your project, it has not actually been loaded into your R environment yet! We'll do that now!

First, you will need to install the read R package, if you haven't already, and then load the library. To do so, input the provided commands. Within this package, there is a function called read underscore csv which will read the file into R. To do so, name the R object with a name that you will call from within R (we've assigned it here to be called df underscore csv), and then call the function to that object name using read underscore csv where you will put the full file name (including the file extension) in quotes between the parentheses. Your data will now be imported into the R environment. If you use the command head D F underscore CSV you will see the first several rows of your imported data frame. 

This is the simplest way to import a CSV file. However, as with many functions, there are other arguments that you can set to specify how to import your specific CSV file. To see all the arguments for this function, use question mark read underscore csv within R.. Of note, are the call underscore names option to specify whether the first row does not contain column names, the skip option to remove the first x number of rows from the data frame, and n underscore max, which will read in the specified number of lines to the data frame. By default, read underscore csv converts blank cells to missing data, coded as NA. Finally, while we introduced the function read underscore csv here and recommend that you use it, as it is the simplest and fastest way to read CSV files into R, we do want you to know that there is a function read dot csv which is available by default in R. You will likely see this function in others' code, so we just want to make sure you're aware of it.

While CSV files hold plain text as a series of values separated by commas, an Excel (or dot XLS or dot XLSX) file holds information in a workbook that comprises both values and formatting (colors, conditional formatting, font size, etc.). You can think of Excel files as a fancier CSV file. While this may sound appealing, we'll remind you that CSV files can be read by many different pieces of software, but Excel files can only be viewed in specific pieces of software, and thus are generally less flexible. That said, many people save their data in Excel, so it's important to know how to work with them in R Studio. Let's go back to the Google Sheet that we created and instead of downloading the file locally as as CSV, download it as Microsoft Excel (dot XLSX) file. 

As before, move the file to the raw_data folder of your project structure so that it is easy to find and read into R..  To read this file into R, we'll have to use a different function than above, as this file is not a CSV file. We'll use the read underscore excel function from the read XL package. Install the package first and then use the function read underscore excel to read the Excel file into your R Environment. As above, by default, read excel converts blank cells to missing data. 

Another common form of data is text files that usually come in the form of TXT or TSV file formats. Like CSVs, text files are simple, plain-text files; however, rather than the columns being separated by commas, they are separated by tabs (represented by backslash t in plain-text). Like CSVs, they don't allow text formatting (e.g. text colors in cells) and are able to be opened on many different software platforms. This makes them good candidates for storing data.

The process for reading these files into R is similar to what you've seen so far. We'll again use the read R package, but we'll instead use the read underscore tsv function. 

Sometimes, tab-separated files are saved with the dot TXT file extension. TXT files can store tabular data, but they can also store simple text. Thus, while TSV is the more appropriate extension for tabular data that are tab-separated, you'll often run into tabular data that individuals have saved as a TXT file. In these cases, you'll want to use the more generic read underscore delim function from read R..  Google Sheets does not allow tab-separated files to be downloaded with the dot TXT file extension (since TSV is more appropriate); however, if you were to have a file "sample underscore data dot TXT" uploaded into your R Studio project, you could use the provided code to read it into your R Environment, where backslash t specifies that the file is tab-delimited. This function allows you to specify how the file you're reading is delimited. This means, rather than R knowing by default whether or not the data are comma- or tab- separated, you'll have to specify it within the argument delim in the function. Read underscore delim is a more generic version of read underscore CSV. What this means is that you could use read delim to read in a CSV file. You would just need to specify that the file was comma-delimited if you were to use that function.

Next, we will talk about how to export data from R..  So far we learned about reading data into R. However, sometimes you would like to share your data with others and thus need to export your data from R to some format that your collaborators can see. As discussed above, CSV format is a good candidate because of its simplicity and compatibility. Let's say you have a data frame in the R environment that you would like to export as a CSV. To do so, you could use write underscore CSV from the read R package. Since we've already created a data frame named df underscore csv, we can export it to a CSV file using the provided code. After typing this command, a new CSV file called my underscore csv underscore file dot CSV will appear in the Files tab and in your project folder. You could similarly save your data as a TSV file using the function write underscore TSV function. We'll finally note that there are default R functions write dot csv and write dot table that accomplish similar goals. You may see these in others' code; however, we recommend sticking to the intuitive and quick read R functions discussed in this lesson.

As a final aside, we are going to go through some of the packages and functions that allow you to quickly view and or preview your R objects that you've just read in. Above, we showed a little bit about how you can use head to see the first few lines of a dataframe or object; there is a related function called tail to see the last few lines of a dataframe or object. In the R console, type question mark head or question mark tail to see some of the options associated with these functions. Of particular note is the N equal argument, to specify how many rows of your dataframe to display. 

Another helpful function is STR which allows you to see the structure of an R object. Let's see how the output of this function compares to head using a dataset included in R, MT cars. So, while head allows you to see how the object is structured and the rownames and some of the data included in the object, STR includes some of the same information, but also tells you what kind of object you are working with (here, data frame) as well as the dimensions of the object (here, 32 observations across 11 variables) and what type of data the observations are (here, they are all numbers, but other classes could include characters or factors, etc.). 

Finally, two functions used to preview and summarize data in R objects include glimpse and skim, from the D plier and skimmer packages, respectively. 

Install these packages, if you haven't already, and then see how their respective functions preview the MT cars dataset. 

From this, we can see that glimpse is fairly similar in output to STR except it displays more observations per variable. skim on the other hand, provides some summary statistics including the number of observations (n), the average (mean), the standard deviation (SD) and even outputs a little histogram of the distribution of your observations within each variable.

In this lesson, we covered how to read in and write out some of the most common file types you will encounter in your data science projects. CSV and TSV files are very similar formats with the column separation being specified by commas and tabs, respectively. Excel files are another common form of tabular data but are not stored as plain-text documents so do require specific software (Excel) or conversion to a plain text format (e.g.: using read underscore Excel). We also looked at some ways to preview or summarize your data, including head, tail, STR, glimpse, and skim.
